{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.hub import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## uncomment if you want to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" config.set_cache_directory(os.path.expanduser('~/openml/cache'))\\nconfig.cachedir = '~/openml/cache' \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openml import datasets, tasks, runs, flows, config, study\n",
    "from openml.datasets import edit_dataset, fork_dataset, get_dataset\n",
    "from openml.tasks import TaskType\n",
    "\n",
    "config.apikey = os.getenv('OPEN_ML_KEY')\n",
    "config.server = 'https://www.openml.org/api/v1'\n",
    "\"\"\" config.set_cache_directory(os.path.expanduser('~/openml/cache'))\n",
    "config.cachedir = '~/openml/cache' \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.list_datasets(output_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset by name\n",
    "dataset = datasets.get_dataset(61)\n",
    "\n",
    "# Get the data itself as a dataframe (or otherwise)\n",
    "data, _, _, _ = dataset.get_data(dataset_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/test split\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing \n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
    "                                                dtype=torch.float), # <- PyTorch loves float32 by default\n",
    "                                   requires_grad=True) # <- can we update this value with gradient descent?)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
    "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
    "                                requires_grad=True) # <- can we update this value with gradient descent?))\n",
    "\n",
    "    # Forward defines the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
    "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode(): \n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# Note: in older PyTorch code you might also see torch.no_grad()\n",
    "# with torch.no_grad():\n",
    "#   y_preds = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 10\n",
      "Number of predictions made: 10\n",
      "Predicted values:\n",
      "tensor([[0.3982],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.4184],\n",
      "        [0.4251],\n",
      "        [0.4318],\n",
      "        [0.4386],\n",
      "        [0.4453],\n",
      "        [0.4520],\n",
      "        [0.4588]])\n"
     ]
    }
   ],
   "source": [
    "# Check the predictions\n",
    "print(f\"Number of testing samples: {len(X_test)}\") \n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function\n",
    "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      "[[[ 1  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]\n",
      "  [13 14]\n",
      "  [15 16]]\n",
      "\n",
      " [[17 18]\n",
      "  [19 20]\n",
      "  [21 22]\n",
      "  [23 24]]]\n",
      "\n",
      "Transposed Array:\n",
      "[[[ 1  2]\n",
      "  [ 9 10]\n",
      "  [17 18]]\n",
      "\n",
      " [[ 3  4]\n",
      "  [11 12]\n",
      "  [19 20]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [13 14]\n",
      "  [21 22]]\n",
      "\n",
      " [[ 7  8]\n",
      "  [15 16]\n",
      "  [23 24]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# CrÃ©er un tableau tridimensionnel de forme (3, 4, 2)\n",
    "X = np.array([[[1, 2], [3, 4], [5, 6], [7, 8]],\n",
    "              [[9, 10], [11, 12], [13, 14], [15, 16]],\n",
    "              [[17, 18], [19, 20], [21, 22], [23, 24]]])\n",
    "\n",
    "# Afficher le tableau original\n",
    "print(\"Original Array:\")\n",
    "print(X)\n",
    "\n",
    "# Transposer le tableau en Ã©changeant les axes 1 et 0\n",
    "X_transposed = X.transpose(1, 0, 2)\n",
    "\n",
    "# Afficher le tableau transposÃ©\n",
    "print(\"\\nTransposed Array:\")\n",
    "print(X_transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['25', '50000', 'City', 'Electronics'], ['30', '60000', 'Suburb', 'Clothing'], ['35', '75000', 'City', 'Electronics'], ['22', '45000', 'Rural', 'Food'], ['28', '55000', 'Suburb', 'Electronics']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Feature2VecPreEncoder(object):\n",
    "\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1, workers=4):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.model = None\n",
    "        self.feature_columns = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Stocker les noms de colonnes des caractÃ©ristiques\n",
    "        self.feature_columns = X.columns.tolist()\n",
    "\n",
    "        # EntraÃ®ner le modÃ¨le Word2Vec sur les donnÃ©es tabulaires\n",
    "        sentences = [X[self.feature_columns].iloc[i].astype(str).tolist() for i in range(len(X))]\n",
    "        print(sentences)\n",
    "        \n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=self.vector_size, window=self.window,\n",
    "                              min_count=self.min_count, workers=self.workers)\n",
    "\n",
    "    def transform(self, X):\n",
    "        # VÃ©rifier si les colonnes de caractÃ©ristiques correspondent Ã  celles utilisÃ©es pendant l'entraÃ®nement\n",
    "        if set(self.feature_columns) != set(X.columns):\n",
    "            raise ValueError(\"Les colonnes de caractÃ©ristiques ne correspondent pas Ã  celles utilisÃ©es pendant l'entraÃ®nement.\")\n",
    "\n",
    "        # Obtenir les embeddings des caractÃ©ristiques\n",
    "        feature_embeddings = np.array([self.model.wv[X.iloc[i].astype(str).tolist()] for i in range(len(X))])\n",
    "        return feature_embeddings\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# CrÃ©er un DataFrame factice\n",
    "data = {'age': [25, 30, 35, 22, 28],\n",
    "        'income': [50000, 60000, 75000, 45000, 55000],\n",
    "        'location': ['City', 'Suburb', 'City', 'Rural', 'Suburb'],\n",
    "        'product_type': ['Electronics', 'Clothing', 'Electronics', 'Food', 'Electronics']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CrÃ©er une instance de Feature2VecPreEncoder\n",
    "feature2vec_encoder = Feature2VecPreEncoder(vector_size=50, window=3, min_count=1, workers=4)\n",
    "\n",
    "# EntraÃ®ner le prÃ©-encodeur\n",
    "feature2vec_encoder.fit(df)\n",
    "\n",
    "# Transformer les caractÃ©ristiques en embeddings\n",
    "df_embeddings = feature2vec_encoder.transform(df)\n",
    "\n",
    "# Afficher les embeddings rÃ©sultants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import OpenmlDataset, OpenmlDatasetLoader\n",
    "from datasets import dataset_train_test_split\n",
    "from preencoder import PreEncoder \n",
    "from models import ToyModel          \n",
    "### example task_ids ###\n",
    "\n",
    "# 361066 bank-marketing\n",
    "# 361076 wine_quality\n",
    "# 361085 sulfur\n",
    "# 361088 superconduct\n",
    "# 361089 california\n",
    "# 361110 electricity\n",
    "# 361111 eye_movements\n",
    "# 361112 KDDCup09_upselling\n",
    "# 361114 rl\n",
    "# 361116 compass\n",
    "# 361099 Bike_Sharing_Demand\n",
    "# 361102 house_sales\n",
    "\n",
    "task_id =  361099 #361076\n",
    "\n",
    "dataset_loader = OpenmlDatasetLoader()\n",
    "dataset = dataset_loader.load(task_id)\n",
    "dataset.print_info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
