{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\n",
      "ERROR: No matching distribution found for PIL\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/adult.csv\")\n",
    "\n",
    "# Transform the target variable to 0,1\n",
    "\n",
    "mapping = {\"<=50K\": 0, \">50K\": 1}\n",
    "df[\"income\"]  = df[\"income\"].map(mapping)\n",
    "\n",
    "X = df.drop(\"income\",axis=1)\n",
    "y = df[\"income\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def show_column_position(dat):\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", size=20)\n",
    "    background = np.array([[0 for _ in range(255)] for _ in range(255)], dtype='uint8')\n",
    "    image = Image.fromarray(background)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((32, 32), str(dat[0][:12]), fill='white', font=font)\n",
    "    draw.text((32, 160), str(dat[1][:11]), fill='white', font=font)\n",
    "    draw.text((160, 32), str(dat[2][:11]), fill='white', font=font)\n",
    "    draw.text((160, 160), str(dat[3][:11]), fill='white', font=font)\n",
    "    rgb = [np.array(image, dtype='uint8') for _ in range(3)]\n",
    "    return np.array(rgb)\n",
    "\n",
    "def show_column_position_another(dat):\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", size=20)\n",
    "    background = np.array([[0 for _ in range(255)] for _ in range(255)], dtype='uint8')\n",
    "    image = Image.fromarray(background)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((32, 32), str(dat[2][:12]), fill='white', font=font)\n",
    "    draw.text((32, 160), str(dat[3][:11]), fill='white', font=font)\n",
    "    draw.text((160, 32), str(dat[1][:11]), fill='white', font=font)\n",
    "    draw.text((160, 160), str(dat[0][:11]), fill='white', font=font)\n",
    "    rgb = [np.array(image, dtype='uint8') for _ in range(3)]\n",
    "    return np.array(rgb)\n",
    "\n",
    "\n",
    "def data_to_image_another(data):\n",
    "    data_images = []\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", size=50)\n",
    "    for dat in data:\n",
    "        background = np.array([[0 for _ in range(255)] for _ in range(255)], dtype='uint8')\n",
    "        image = Image.fromarray(background)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.text((32, 32), str(dat[2]), fill='white', font=font)\n",
    "        draw.text((32, 160), str(dat[3]), fill='white', font=font)\n",
    "        draw.text((160, 32), str(dat[1]), fill='white', font=font)\n",
    "        draw.text((160, 160), str(dat[0]), fill='white', font=font)\n",
    "        rgb = [np.array(image, dtype='uint8') for _ in range(3)]\n",
    "        data_images.append(rgb)\n",
    "    return np.array(data_images) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_res = models.resnet18(weights=True)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_image(data):\n",
    "    \n",
    "    data_images = []\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=50)\n",
    "    for dat in data.values:\n",
    "        background = np.array([[0 for _ in range(255)] for _ in range(255)], dtype='uint8')\n",
    "        image = Image.fromarray(background)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        y_offset = 32  # Décalage initial en y\n",
    "        x_offset = 32  # Décalage initial en x\n",
    "        \n",
    "        for i, value in enumerate(dat):\n",
    "            draw.text((x_offset, y_offset), str(value), fill='white', font=font)\n",
    "            y_offset += 128  # Ajustement de la position en y pour la prochaine valeur\n",
    "            if i % 2 != 0:\n",
    "                y_offset = 32  # Réinitialisation du décalage en y après chaque deuxième valeur\n",
    "                x_offset += 128  # Décalage en x pour la prochaine ligne\n",
    "\n",
    "        rgb = [np.array(image, dtype='uint8') for _ in range(3)]\n",
    "        data_images.append(rgb)\n",
    "    return np.array(data_images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from sklearn.datasets import load_iris\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(iris_data.data, iris_data.target, stratify=iris_data.target, test_size=0.2, random_state=0)\n",
    "\n",
    "train_images = data_to_image(X_train)\n",
    "val_images = data_to_image(X_val)\n",
    "\n",
    "\"\"\" print(train_images.shape)\n",
    "print(val_images.shape)\n",
    "plt.grid()\n",
    "plt.imshow(train_images[2][0, :, :]) \"\"\"\n",
    "\n",
    "\n",
    "X_train = torch.from_numpy(train_images).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_val = torch.from_numpy(val_images).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "dataloaders = {'train': DataLoader(train_dataset, batch_size=16, shuffle=True),\n",
    "              'val': DataLoader(val_dataset)}\n",
    "\n",
    "dataset_sizes = {'train': len(X_train),\n",
    "                'val': len(X_val)} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.10 GiB for an array with shape (39073, 3, 255, 255) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mdata_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_images \u001b[38;5;241m=\u001b[39m data_to_image(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_images\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[61], line 22\u001b[0m, in \u001b[0;36mdata_to_image\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     20\u001b[0m     rgb \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(image, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m     21\u001b[0m     data_images\u001b[38;5;241m.\u001b[39mappend(rgb)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data_images) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.10 GiB for an array with shape (39073, 3, 255, 255) and data type uint8"
     ]
    }
   ],
   "source": [
    "train_images = data_to_image(X_train)\n",
    "test_images = data_to_image(X_test)\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.imshow(train_images[1][2, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_images)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      9\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_test\u001b[38;5;241m.\u001b[39mto_numpy())\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 11\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(X_test, y_test)\n\u001b[0;32m     14\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     15\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: DataLoader(val_dataset)}\n",
      "File \u001b[1;32mc:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:204\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = torch.from_numpy(train_images).float()\n",
    "y_train = torch.from_numpy(y_train.squeeze().to_numpy()).long()\n",
    "X_test = torch.from_numpy(test_images).float()\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "dataloaders = {'train': DataLoader(train_dataset, batch_size=16, shuffle=True),\n",
    "              'val': DataLoader(val_dataset)}\n",
    "\n",
    "dataset_sizes = {'train': len(X_train),\n",
    "                'val': len(X_test)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Echec de la mission problème de mémoire pour de grands datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
