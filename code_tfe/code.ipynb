{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.hub import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## uncomment if you want to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Dataset name: Bike_Sharing_Demand\n",
      "n_samples: 17379\n",
      "m_features: 11 (including 5 categorical features)\n",
      "Task: regression\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import OpenmlDataset, OpenmlDatasetLoader\n",
    "from datasets import dataset_train_test_split\n",
    "from preencoder import PreEncoder \n",
    "import numpy as np\n",
    "from models import ToyModel          \n",
    "### example task_ids ###\n",
    "\n",
    "# 361066 bank-marketing\n",
    "# 361076 wine_quality\n",
    "# 361085 sulfur\n",
    "# 361088 superconduct\n",
    "# 361089 california\n",
    "# 361110 electricity\n",
    "# 361111 eye_movements\n",
    "# 361112 KDDCup09_upselling\n",
    "# 361114 rl\n",
    "# 361116 compass\n",
    "# 361099 Bike_Sharing_Demand\n",
    "# 361102 house_sales\n",
    "\n",
    "task_id =  361099 #361076\n",
    "\n",
    "dataset_loader = OpenmlDatasetLoader()\n",
    "dataset = dataset_loader.load(task_id)\n",
    "dataset.print_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>feel_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season year  month  hour holiday workingday weather   temp  feel_temp  \\\n",
       "0          1    0      1     0       0          0       0   9.84     14.395   \n",
       "1          1    0      1     1       0          0       0   9.02     13.635   \n",
       "2          1    0      1     2       0          0       0   9.02     13.635   \n",
       "3          1    0      1     3       0          0       0   9.84     14.395   \n",
       "4          1    0      1     4       0          0       0   9.84     14.395   \n",
       "...      ...  ...    ...   ...     ...        ...     ...    ...        ...   \n",
       "17374      1    1     12    19       0          1       2  10.66     12.880   \n",
       "17375      1    1     12    20       0          1       2  10.66     12.880   \n",
       "17376      1    1     12    21       0          1       0  10.66     12.880   \n",
       "17377      1    1     12    22       0          1       0  10.66     13.635   \n",
       "17378      1    1     12    23       0          1       0  10.66     13.635   \n",
       "\n",
       "       humidity  windspeed  \n",
       "0          0.81     0.0000  \n",
       "1          0.80     0.0000  \n",
       "2          0.80     0.0000  \n",
       "3          0.75     0.0000  \n",
       "4          0.75     0.0000  \n",
       "...         ...        ...  \n",
       "17374      0.60    11.0014  \n",
       "17375      0.60    11.0014  \n",
       "17376      0.60    11.0014  \n",
       "17377      0.56     8.9981  \n",
       "17378      0.65     8.9981  \n",
       "\n",
       "[17379 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comme nous sommes en static embedding, on prefere avoir un set de valeurs de chaque colonne\n",
    "\n",
    "features = {}\n",
    "for i in dataset.X.columns :\n",
    "    features[i] = set(dataset.X[i].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les \"phrases\" ici sont les row du dataset, donc pour un element quelconque, avoir la liste de ses lignes d'occurence, prendre les valeurs de sa fenetre contextuelle et constituer ses positives examples; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 'season'), ('2', 'season'), ('1', 'season'), ('0', 'season'), ('1', 'year'), ('0', 'year'), (1, 'month'), (2, 'month'), (3, 'month'), (4, 'month'), (5, 'month'), (6, 'month'), (7, 'month'), (8, 'month'), (9, 'month'), (10, 'month'), (11, 'month'), (12, 'month'), (0, 'hour'), (1, 'hour'), (2, 'hour'), (3, 'hour'), (4, 'hour'), (5, 'hour'), (6, 'hour'), (7, 'hour'), (8, 'hour'), (9, 'hour'), (10, 'hour'), (11, 'hour'), (12, 'hour'), (13, 'hour'), (14, 'hour'), (15, 'hour'), (16, 'hour'), (17, 'hour'), (18, 'hour'), (19, 'hour'), (20, 'hour'), (21, 'hour'), (22, 'hour'), (23, 'hour'), ('1', 'holiday'), ('0', 'holiday'), ('1', 'workingday'), ('0', 'workingday'), ('3', 'weather'), ('2', 'weather'), ('1', 'weather'), ('0', 'weather'), (0.8200000000000001, 'temp'), (1.6400000000000001, 'temp'), (2.46, 'temp'), (3.2800000000000002, 'temp'), (4.92, 'temp'), (5.74, 'temp'), (6.5600000000000005, 'temp'), (7.38, 'temp'), (8.200000000000001, 'temp'), (9.84, 'temp'), (9.02, 'temp'), (10.66, 'temp'), (12.299999999999999, 'temp'), (13.120000000000001, 'temp'), (14.76, 'temp'), (15.58, 'temp'), (16.400000000000002, 'temp'), (17.22, 'temp'), (18.86, 'temp'), (18.04, 'temp'), (13.940000000000001, 'temp'), (21.32, 'temp'), (22.96, 'temp'), (23.779999999999998, 'temp'), (24.599999999999998, 'temp'), (19.68, 'temp'), (22.14, 'temp'), (20.5, 'temp'), (27.060000000000002, 'temp'), (26.240000000000002, 'temp'), (25.419999999999998, 'temp'), (27.880000000000003, 'temp'), (28.7, 'temp'), (30.34, 'temp'), (31.16, 'temp'), (29.52, 'temp'), (31.98, 'temp'), (33.62, 'temp'), (32.800000000000004, 'temp'), (35.26, 'temp'), (36.08, 'temp'), (36.9, 'temp'), (34.44, 'temp'), (37.72, 'temp'), (38.54, 'temp'), (39.36, 'temp'), (40.18, 'temp'), (41.0, 'temp'), (11.48, 'temp'), (4.1000000000000005, 'temp'), (0.0, 'feel_temp'), (1.5150000000000001, 'feel_temp'), (2.275, 'feel_temp'), (3.0300000000000002, 'feel_temp'), (3.7900000000000005, 'feel_temp'), (5.305, 'feel_temp'), (6.819999999999999, 'feel_temp'), (6.0600000000000005, 'feel_temp'), (8.334999999999999, 'feel_temp'), (9.85, 'feel_temp'), (10.605, 'feel_temp'), (11.365, 'feel_temp'), (12.879999999999999, 'feel_temp'), (13.635, 'feel_temp'), (14.395, 'feel_temp'), (9.09, 'feel_temp'), (16.665, 'feel_temp'), (17.424999999999997, 'feel_temp'), (12.120000000000001, 'feel_temp'), (19.695, 'feel_temp'), (20.455000000000002, 'feel_temp'), (21.21, 'feel_temp'), (22.725, 'feel_temp'), (21.97, 'feel_temp'), (15.909999999999998, 'feel_temp'), (4.545, 'feel_temp'), (0.76, 'feel_temp'), (18.18, 'feel_temp'), (25.0, 'feel_temp'), (26.515, 'feel_temp'), (27.275, 'feel_temp'), (29.544999999999998, 'feel_temp'), (23.485, 'feel_temp'), (25.759999999999998, 'feel_temp'), (31.06, 'feel_temp'), (30.305, 'feel_temp'), (31.819999999999997, 'feel_temp'), (32.574999999999996, 'feel_temp'), (33.335, 'feel_temp'), (34.089999999999996, 'feel_temp'), (34.85, 'feel_temp'), (37.12, 'feel_temp'), (38.635000000000005, 'feel_temp'), (37.88, 'feel_temp'), (36.364999999999995, 'feel_temp'), (40.15, 'feel_temp'), (39.395, 'feel_temp'), (41.665, 'feel_temp'), (40.910000000000004, 'feel_temp'), (35.605, 'feel_temp'), (42.425000000000004, 'feel_temp'), (43.94, 'feel_temp'), (43.18, 'feel_temp'), (44.695, 'feel_temp'), (46.21, 'feel_temp'), (47.725, 'feel_temp'), (49.24, 'feel_temp'), (50.0, 'feel_temp'), (28.79, 'feel_temp'), (15.15, 'feel_temp'), (18.94, 'feel_temp'), (28.03, 'feel_temp'), (45.455, 'feel_temp'), (7.575, 'feel_temp'), (24.240000000000002, 'feel_temp'), (0.81, 'humidity'), (0.8, 'humidity'), (0.76, 'humidity'), (0.75, 'humidity'), (0.77, 'humidity'), (0.72, 'humidity'), (1.0, 'humidity'), (0.5, 'humidity'), (0.51, 'humidity'), (0.26, 'humidity'), (0.25, 'humidity'), (0.0, 'humidity'), (0.84, 'humidity'), (0.21, 'humidity'), (0.54, 'humidity'), (0.23, 'humidity'), (0.22, 'humidity'), (0.79, 'humidity'), (0.63, 'humidity'), (0.38, 'humidity'), (0.13, 'humidity'), (0.47, 'humidity'), (0.97, 'humidity'), (0.42, 'humidity'), (0.43, 'humidity'), (0.18, 'humidity'), (0.44, 'humidity'), (0.19, 'humidity'), (0.45, 'humidity'), (0.46, 'humidity'), (0.41, 'humidity'), (0.2, 'humidity'), (0.6, 'humidity'), (0.85, 'humidity'), (0.94, 'humidity'), (0.69, 'humidity'), (0.16, 'humidity'), (0.15, 'humidity'), (0.17, 'humidity'), (0.55, 'humidity'), (0.39, 'humidity'), (0.64, 'humidity'), (0.14, 'humidity'), (0.89, 'humidity'), (0.48, 'humidity'), (0.73, 'humidity'), (0.57, 'humidity'), (0.86, 'humidity'), (0.82, 'humidity'), (0.88, 'humidity'), (0.87, 'humidity'), (0.59, 'humidity'), (0.92, 'humidity'), (0.58, 'humidity'), (0.67, 'humidity'), (0.35, 'humidity'), (0.68, 'humidity'), (0.93, 'humidity'), (0.52, 'humidity'), (0.27, 'humidity'), (0.91, 'humidity'), (0.36, 'humidity'), (0.61, 'humidity'), (0.7, 'humidity'), (0.1, 'humidity'), (0.08, 'humidity'), (0.56, 'humidity'), (0.4, 'humidity'), (0.65, 'humidity'), (0.9, 'humidity'), (0.74, 'humidity'), (0.49, 'humidity'), (0.24, 'humidity'), (0.83, 'humidity'), (0.34, 'humidity'), (0.29, 'humidity'), (0.3, 'humidity'), (0.31, 'humidity'), (0.32, 'humidity'), (0.33, 'humidity'), (0.28, 'humidity'), (0.53, 'humidity'), (0.78, 'humidity'), (0.37, 'humidity'), (0.62, 'humidity'), (0.12, 'humidity'), (0.71, 'humidity'), (0.96, 'humidity'), (0.66, 'humidity'), (0.0, 'windspeed'), (6.0032, 'windspeed'), (7.0015, 'windspeed'), (8.9981, 'windspeed'), (11.0014, 'windspeed'), (12.998, 'windspeed'), (15.001299999999999, 'windspeed'), (16.997899999999998, 'windspeed'), (19.0012, 'windspeed'), (19.999499999999998, 'windspeed'), (22.0028, 'windspeed'), (23.9994, 'windspeed'), (26.0027, 'windspeed'), (27.999299999999998, 'windspeed'), (30.002599999999997, 'windspeed'), (31.0009, 'windspeed'), (32.9975, 'windspeed'), (35.0008, 'windspeed'), (36.9974, 'windspeed'), (39.000699999999995, 'windspeed'), (40.9973, 'windspeed'), (43.9989, 'windspeed'), (43.000600000000006, 'windspeed'), (46.0022, 'windspeed'), (47.9988, 'windspeed'), (50.0021, 'windspeed'), (51.9987, 'windspeed'), (54.001999999999995, 'windspeed'), (55.998599999999996, 'windspeed'), (56.996900000000004, 'windspeed')]\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for k,v in features.items() : \n",
    "    for i in v:\n",
    "        vocab.append((i,k))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(vocab)\n",
    "emb = np.zeros(N)\n",
    "d=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les lignes des matrices de poids sont les embeddings que nous cherchons Ã  obtenir.\n",
    "Input de taille N\\*N et matrice de poids de la Layer 1 est  de taille N*d, d Ã©tant la taille de l'mebdding qu'on souhaite avoir; 2e matrice de poids de taille d\\*N. Dernier layer un softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def init_network(vocab_size, n_embedding):\n",
    "    model = {\n",
    "        \"w1\": np.random.randn(N, d),\n",
    "        \"w2\": np.random.randn(d, N)\n",
    "    }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x)\n",
    "        res.append(exp / exp.sum())\n",
    "    return res\n",
    "\n",
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "    \n",
    "    cache[\"a1\"] = X @ model[\"w1\"]\n",
    "    cache[\"a2\"] = cache[\"a1\"] @ model[\"w2\"]\n",
    "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
    "    \n",
    "    if not return_cache:\n",
    "        return cache[\"z\"]\n",
    "    return cache\n",
    "\n",
    "\n",
    "def cross_entropy(z, y):\n",
    "    return - np.sum(np.log(z) * y)\n",
    "\n",
    "def backward(model, X, y, alpha):\n",
    "    cache  = forward(model, X)\n",
    "    da2 = cache[\"z\"] - y\n",
    "    dw2 = cache[\"a1\"].T @ da2\n",
    "    da1 = da2 @ model[\"w2\"].T\n",
    "    dw1 = X.T @ da1\n",
    "    assert(dw2.shape == model[\"w2\"].shape)\n",
    "    assert(dw1.shape == model[\"w1\"].shape)\n",
    "    model[\"w1\"] -= alpha * dw1\n",
    "    model[\"w2\"] -= alpha * dw2\n",
    "    return cross_entropy(cache[\"z\"], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Machine learning is the study of computer algorithms that \\\n",
    "improve automatically through experience. It is seen as a \\\n",
    "subset of artificial intelligence. Machine learning algorithms \\\n",
    "build a mathematical model based on sample data, known as \\\n",
    "training data, in order to make predictions or decisions without \\\n",
    "being explicitly programmed to do so. Machine learning algorithms \\\n",
    "are used in a wide variety of applications, such as email filtering \\\n",
    "and computer vision, where it is difficult or infeasible to develop \\\n",
    "conventional algorithms to perform the needed tasks.'''\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(tokens):\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        word_to_id[token] = i\n",
    "        id_to_word[i] = token\n",
    "    \n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = mapping(vocab)\n",
    "\n",
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable\n",
    "\n",
    "def one_hot_encode(id, vocab_size):\n",
    "    res = [0] * vocab_size\n",
    "    res[id] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_tokens = len(tokens)\n",
    "    \n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i), \n",
    "            range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "        \n",
    "        for j in idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            X.append(one_hot_encode(word_to_id[tokens[i]], len(word_to_id)))\n",
    "            y.append(one_hot_encode(word_to_id[tokens[j]], len(word_to_id)))\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_training_data(vocab, word_to_id, 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_network(len(word_to_id), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1130, 284)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ model[\"w1\"] @ model[\"w2\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'season'),\n",
       " ('3', 'season'),\n",
       " ('0', 'season'),\n",
       " ('2', 'season'),\n",
       " ('1', 'year')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "learning_rate = 0.05\n",
    "\n",
    "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = one_hot_encode(word_to_id[('1', 'year')], len(word_to_id))\n",
    "result = forward(model, [learning], return_cache=False)[0]\n",
    "\n",
    "for word in (id_to_word[id] for id in np.argsort(result)[::-1]):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24821374, -0.05306013,  2.48466276, -2.0990956 , -1.4571657 ],\n",
       "       [-0.03794926,  1.68185175,  1.96142912, -2.89671142, -1.52873487],\n",
       "       [-0.63450616,  0.66431115,  2.27075283, -2.22860081, -2.39177609],\n",
       "       ...,\n",
       "       [ 0.84551666,  0.78100398,  2.79673533,  1.05317667,  1.70565515],\n",
       "       [ 0.83825526,  0.44006153,  2.5116818 ,  2.7237128 ,  1.95792313],\n",
       "       [ 1.10797885,  1.0960138 ,  2.04695966,  1.29541145,  2.49473848]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"w1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire une deuxiÃ¨me lookup table pour un mapping (valeurs, features ) --> embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
